{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed570ed7",
   "metadata": {},
   "source": [
    "## Dragon Riders\n",
    "\n",
    "### Feature generation and Classical ML\n",
    "\n",
    "Part of Grigoriy Kryukov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8ec1cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "71cc545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "93ba472d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6d0bb734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home.\\n\\nThe hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear.\\n\\nmost students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go.\\n\\nwhen your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class.              \""
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce00600",
   "metadata": {},
   "source": [
    "I have no doubt that advanced models, such as DeBERTaV3, will cope with the task much better than the methods of classical ML. However, our course is ML, not DL. Therefore, at least one person from the team should show the power of classical methods.\n",
    "\n",
    "To apply classical methods, we need features. I deliberately refuse pre-irradiated embeddings and try to show imagination and knowledge of computational linguistics.\n",
    "\n",
    "Let's list a list of features that could potentially be useful.\n",
    "\n",
    "- $\\textbf{The number of tokens}$. To count them, we use the nltk.tokenize.word_tokenize. There is a hypothesis that the better a person knows the language, the more voluminous an essay he can write.\n",
    "- $\\textbf{The number of words and ratio words/tokens}$. Clearing tokens from punctuation. Perhaps a more literate person will use more punctuation marks.\n",
    "- $\\textbf{The number and share of words not included in the list nltk.corpus.stopwords}$. (Frequently used words that do not carry a semantic load). There are two hypotheses here. On the one hand, the less a person uses stop words, the more diverse and meaningful speech. On the other hand, a person who does not know English well may forget about the stop words \"a\", \"the\" and the like.\n",
    "- $\\textbf{The average and median length of words}$. Perhaps the longer the words, the more complex they are and the better the person using them knows English.\n",
    "- $\\textbf{The number of sentences}$. There is a hypothesis that the better a person knows the language, the more sentences he can leave.\n",
    "- $\\textbf{The average and median length of sentences}$. There are two hypotheses here. On the one hand, a person who does not know English well is able to compose only short sentences. On the one hand, a person who does not know English well may compose sentences that are too long with a large number of words. Which is often not natural for English.\n",
    "- $\\textbf{The number of uses of a part of speech}$. The hypothesis is that in the letter of a person who does not know English well, there will be many prepositions (for example, 'of'). Conversely, an expert in English will use rare parts of speech, such as adverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b318400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'before', \"don't\", 'here', 'm', 'on', 'shouldn', 'through', 'who']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of stop words\n",
    "stop_words = sorted(stopwords.words('english'))\n",
    "stop_words[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18c82dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3911/3911 [01:30<00:00, 43.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# set of parts of speech\n",
    "\n",
    "tags = []\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    tokens = word_tokenize(df['full_text'][i])\n",
    "    clean_words = [w.strip(punct) for w in tokens if w.strip(punct)]\n",
    "    pos = pos_tag(clean_words, tagset = \"universal\")\n",
    "    for j in range(len(clean_words)):\n",
    "        tags.append(pos[j][1])\n",
    "\n",
    "tags = list(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5d9ad2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'VERB',\n",
       " 'DET',\n",
       " 'X',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " '.',\n",
       " 'PRT']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a3191c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3911/3911 [08:17<00:00,  7.87it/s]\n"
     ]
    }
   ],
   "source": [
    "N = len(df)\n",
    "\n",
    "punct = '!\"#$%&()*\\+,-\\./:;<=>?@\\[\\]^_`{|}~„“«»†*\\—/\\-–‘’'\n",
    "stop_words = sorted(stopwords.words('english'))\n",
    "\n",
    "for tag in tags:\n",
    "    df[tag] = np.zeros(N)\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    tokens = word_tokenize(df['full_text'][i])\n",
    "    df.loc[i, \"num_tokens\"] = len(tokens)\n",
    "    clean_words = [w.strip(punct) for w in tokens if w.strip(punct)]\n",
    "    df.loc[i, \"num_punct\"] = len(clean_words)\n",
    "    df.loc[i, \"share_punct\"] = 1 - len(clean_words) / len(tokens)\n",
    "    good_words = [w for w in clean_words if w not in stop_words]\n",
    "    df.loc[i, \"num_nonstop\"] = len(good_words)\n",
    "    df.loc[i, \"share_nonstop\"] = len(good_words) / len(clean_words)\n",
    "    arrlen = np.array([len(w) for w in good_words])\n",
    "    df.loc[i, \"avglen\"] = arrlen.mean()\n",
    "    df.loc[i, \"medlen\"] = np.median(arrlen)\n",
    "    sents = sent_tokenize(df['full_text'][i])\n",
    "    df.loc[i, \"num_sents\"] = len(sents)\n",
    "    sentlen = np.array([len(word_tokenize(s)) for s in sents])\n",
    "    df.loc[i, \"avgsentlen\"] = sentlen.mean()\n",
    "    df.loc[i, \"medsentlen\"] = np.median(sentlen)\n",
    "    pos = pos_tag(clean_words, tagset = \"universal\")\n",
    "    for p in pos:\n",
    "        if p[1] in tags:\n",
    "            df.loc[i, p[1]] += 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33ae8c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>...</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>num_punct</th>\n",
       "      <th>share_punct</th>\n",
       "      <th>num_nonstop</th>\n",
       "      <th>share_nonstop</th>\n",
       "      <th>avglen</th>\n",
       "      <th>medlen</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>avgsentlen</th>\n",
       "      <th>medsentlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>283.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>5.111940</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.722222</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>554.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>0.032491</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.421642</td>\n",
       "      <td>5.376106</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.571429</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>356.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.073034</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.769697</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.736842</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>836.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>5.073864</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.222222</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.478632</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions   PRON  NOUN  ...  \\\n",
       "0     3.5         3.0          3.0      4.0          3.0   33.0  47.0  ...   \n",
       "1     2.5         3.0          2.0      2.0          2.5   63.0  89.0  ...   \n",
       "2     3.5         3.0          3.0      3.0          2.5   34.0  70.0  ...   \n",
       "3     4.5         4.5          4.5      4.0          5.0  138.0  93.0  ...   \n",
       "4     3.0         3.0          3.0      2.5          2.5   31.0  59.0  ...   \n",
       "\n",
       "   num_tokens  num_punct  share_punct  num_nonstop  share_nonstop    avglen  \\\n",
       "0       283.0      264.0     0.067138        134.0       0.507576  5.111940   \n",
       "1       554.0      536.0     0.032491        226.0       0.421642  5.376106   \n",
       "2       356.0      330.0     0.073034        165.0       0.500000  4.769697   \n",
       "3       836.0      759.0     0.092105        352.0       0.463768  5.073864   \n",
       "4       237.0      234.0     0.012658        112.0       0.478632  5.437500   \n",
       "\n",
       "   medlen  num_sents  avgsentlen  medsentlen  \n",
       "0     5.0       18.0   15.722222        14.5  \n",
       "1     5.0       14.0   39.571429        25.0  \n",
       "2     4.0       19.0   18.736842        19.0  \n",
       "3     5.0       36.0   23.222222        22.5  \n",
       "4     6.0        3.0   79.000000        42.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99164292",
   "metadata": {},
   "source": [
    "The data is ready. Now we split the sample into train and test to evaluate the quality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d8f95e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, train_size = 0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ac9e659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRON', 'NOUN', 'NUM', 'ADV', 'CONJ', 'VERB', 'DET', 'X', 'ADJ', 'ADP',\n",
       "       '.', 'PRT', 'num_tokens', 'num_punct', 'share_punct', 'num_nonstop',\n",
       "       'share_nonstop', 'avglen', 'medlen', 'num_sents', 'avgsentlen',\n",
       "       'medsentlen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns[8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5903edc7",
   "metadata": {},
   "source": [
    "Now we implement a function that takes machine learning models as input, trains on a training sample and returns RMSE for a test sample.\n",
    "\n",
    "Since we have six target metrics, the RMSE will be calculated for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "16ebccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[list(train.columns)[8:]]\n",
    "X_test = test[list(test.columns)[8:]]\n",
    "y_col = list(train.columns[2:8])\n",
    "\n",
    "def estimate_RMSE(main_model):\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for col in y_col:\n",
    "        model = main_model\n",
    "        model.fit(X_train, train[col])\n",
    "        models.append(model)\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    for model in models:\n",
    "        preds.append(model.predict(X_test))\n",
    "        \n",
    "    RMSE = np.zeros(len(preds))\n",
    "    for i in range(len(preds)):\n",
    "        RMSE[i] = MSE(test[y_col[i]], preds[i], squared=False)\n",
    "        \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab96daf",
   "metadata": {},
   "source": [
    "Let's try to apply different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "78332bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "307947ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5835, 0.5805, 0.5378, 0.6022, 0.6515, 0.5989],\n",
       "       [0.5831, 0.5806, 0.5378, 0.6021, 0.6515, 0.5993],\n",
       "       [0.6159, 0.6133, 0.5561, 0.6301, 0.6806, 0.6457],\n",
       "       [0.5927, 0.5878, 0.5431, 0.6099, 0.6563, 0.6194],\n",
       "       [0.6373, 0.6608, 0.5887, 0.6555, 0.7058, 0.6681],\n",
       "       [0.8541, 0.8331, 0.8301, 0.8588, 0.8826, 0.8725],\n",
       "       [0.5876, 0.5824, 0.5376, 0.6128, 0.6534, 0.615 ],\n",
       "       [0.5927, 0.5987, 0.5384, 0.6182, 0.6704, 0.6278],\n",
       "       [0.6326, 0.621 , 0.5838, 0.6482, 0.6877, 0.6442]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_models = [LinearRegression(), Ridge(), Lasso(), SVR(), KNeighborsRegressor(),\n",
    "         DecisionTreeRegressor(random_state=42), RandomForestRegressor(random_state=42),\n",
    "         AdaBoostRegressor(random_state=42), XGBRegressor(random_state=42)]\n",
    "\n",
    "scores = np.zeros((len(main_models), len(y_col)))\n",
    "for i, model in enumerate(main_models):\n",
    "    scores[i] = estimate_RMSE(model)\n",
    "    \n",
    "scores.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a074a2c",
   "metadata": {},
   "source": [
    "The best average result is shown by linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d169d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.592 0.592 0.624 0.602 0.653 0.855 0.598 0.608 0.636]\n",
      "LinearRegression()\n"
     ]
    }
   ],
   "source": [
    "MCRMSE = scores.mean(axis=1)\n",
    "print(MCRMSE.round(3))\n",
    "print(main_models[np.argmin(MCRMSE)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a355a8",
   "metadata": {},
   "source": [
    "However, we can use different models to predict different metrics!\n",
    "\n",
    "Let's find out which models did a better job of predicting different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bdc75ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models:\n",
      "\n",
      "cohesion Ridge()\n",
      "syntax LinearRegression()\n",
      "vocabulary RandomForestRegressor(random_state=42)\n",
      "phraseology Ridge()\n",
      "grammar LinearRegression()\n",
      "conventions LinearRegression()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best models:\")\n",
    "print()\n",
    "for i in range(len(y_col)):\n",
    "    ind_best = np.argmin(scores, axis=0)\n",
    "    print(y_col[i], main_models[ind_best[i]])\n",
    "    np.argmin(scores, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd77745",
   "metadata": {},
   "source": [
    "We use these models.\n",
    "\n",
    "On the internal test, a score of $0.59$ was obtained.\n",
    "\n",
    "The score on the kaggle public leaderboard was higher. $0.56$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "baa59ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5922862069064257"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(scores, axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a878a",
   "metadata": {},
   "source": [
    "![score1](./score1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc60e6",
   "metadata": {},
   "source": [
    "This is only $0.13$ behind the first place.\n",
    "\n",
    "We can say that we were able to get a good intermediate result without using embeddings and neural networks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
